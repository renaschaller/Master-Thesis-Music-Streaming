{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e98f7c42",
   "metadata": {},
   "source": [
    "## Data Extraction Process\n",
    "\n",
    "To build the analytical dataset, we combined multiple raw CSV sources from the NetEase Cloud Music (NCM) platform:\n",
    "\n",
    "1) User Selection:\n",
    "We first identify all users with registeredMonthCnt = 0 from user_demographics.csv. This group represents newly registered users, which are the focus of our analysis.\n",
    "2) Impression Collection:\n",
    "For these users, we extract all available impressions from impression_data.csv (no per-user cap). Each impression contains engagement signals such as clicks, likes, shares, and view times.\n",
    "3) Dimensional Joins:\n",
    "The impressions are enriched with static user, card (mlog), and creator metadata by joining:\n",
    "user_demographics.csv on userId\n",
    "mlog_demographics.csv on mlogId\n",
    "creator_demographics.csv on creatorId\n",
    "4) Behavioral Statistics:\n",
    "Two additional datasets provide aggregated behavioral context:\n",
    "mlog_stats.csv (joined on mlogId and dt) adds mlog-level engagement counts.\n",
    "creator_stats.csv (joined on creatorId and dt) adds creator-level posting activity.\n",
    "\n",
    "#### Post-processing and Output:\n",
    "The merged dataset is cleaned, type-casted, and deduplicated. A binary label y_active is created, where users with user_level ≥ 5 are marked as active.\n",
    "The final dataset is saved at the impression level (one row per impression event)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e8c143c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users with registeredMonthCnt = 0: 27,725\n",
      "Collected impressions: 390,166\n",
      "Saved: ../data/recently_registered_users.csv\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ---------------------------\n",
    "# Config\n",
    "# ---------------------------\n",
    "DATA_DIR = Path(\"../csv_data\")         \n",
    "OUT_DIR = Path(\"../data\")\n",
    "OUT_CSV = OUT_DIR / \"recently_registered_users.csv\"  \n",
    "\n",
    "CHUNKSIZE = 250_000\n",
    "\n",
    "# Raw file paths\n",
    "IMP_PATH = DATA_DIR / \"impression_data.csv\"\n",
    "USR_PATH = DATA_DIR / \"user_demographics.csv\"\n",
    "CRD_PATH = DATA_DIR / \"mlog_demographics.csv\"\n",
    "CRT_PATH = DATA_DIR / \"creator_demographics.csv\"\n",
    "MLOG_STATS_PATH = DATA_DIR / \"mlog_stats.csv\"\n",
    "CREATOR_STATS_PATH = DATA_DIR / \"creator_stats.csv\"\n",
    "\n",
    "# ---------------------------\n",
    "# Helpers\n",
    "# ---------------------------\n",
    "def users_with_registered_month_zero(user_csv, chunksize=CHUNKSIZE):\n",
    "    \"\"\"\n",
    "    Return the set of userIds with registeredMonthCnt == 0.\n",
    "    No sampling; scans the user_demographics.csv once in chunks.\n",
    "    \"\"\"\n",
    "    keep = []\n",
    "    usecols = [\"userId\", \"registeredMonthCnt\"]\n",
    "    dtypes = {\"userId\": \"string\", \"registeredMonthCnt\": \"Int64\"}\n",
    "    for chunk in pd.read_csv(user_csv, usecols=usecols, chunksize=chunksize, dtype=dtypes):\n",
    "        sel = chunk.loc[chunk[\"registeredMonthCnt\"].fillna(-1).eq(0), \"userId\"].dropna().astype(\"string\")\n",
    "        if not sel.empty:\n",
    "            keep.append(sel)\n",
    "    if not keep:\n",
    "        return set()\n",
    "    return set(pd.concat(keep, ignore_index=True).unique())\n",
    "\n",
    "def read_filtered(path, key_col, keep_keys, usecols, chunksize=CHUNKSIZE):\n",
    "    \"\"\"\n",
    "    Semi-join reader: only rows whose key_col ∈ keep_keys are returned.\n",
    "    \"\"\"\n",
    "    keep_keys = {str(x) for x in pd.Series(list(keep_keys)).dropna().unique()}\n",
    "    parts = []\n",
    "    for chunk in pd.read_csv(path, usecols=usecols, chunksize=chunksize, dtype={key_col: \"string\"}):\n",
    "        chunk[key_col] = chunk[key_col].astype(\"string\")\n",
    "        sel = chunk[chunk[key_col].isin(keep_keys)]\n",
    "        if not sel.empty:\n",
    "            parts.append(sel)\n",
    "    return pd.concat(parts, ignore_index=True) if parts else pd.DataFrame(columns=usecols)\n",
    "\n",
    "def read_filtered_two_keys(path, key_cols, keep_pairs, usecols, chunksize=CHUNKSIZE, dtypes=None):\n",
    "    \"\"\"\n",
    "    Semi-join reader for composite key (k1, k2) using string-normalized composite keys.\n",
    "    Works safely with pandas nullable dtypes (e.g., Int64Dtype).\n",
    "    \"\"\"\n",
    "    k1, k2 = key_cols\n",
    "\n",
    "    # --- build keep_set of \"k1|k2\" strings ---\n",
    "    pairs_df = pd.DataFrame(keep_pairs, columns=[k1, k2]).dropna()\n",
    "    if not pairs_df.empty:\n",
    "        pairs_df[k1] = pairs_df[k1].astype(\"string\")\n",
    "        # force numeric then to nullable int for consistent stringification\n",
    "        pairs_df[k2] = pd.to_numeric(pairs_df[k2], errors=\"coerce\").astype(\"Int64\")\n",
    "        keep_set = set((pairs_df[k1].astype(\"string\") + \"|\" + pairs_df[k2].astype(\"string\")).tolist())\n",
    "    else:\n",
    "        keep_set = set()\n",
    "\n",
    "    if dtypes is None:\n",
    "        dtypes = {}\n",
    "\n",
    "    parts = []\n",
    "    for chunk in pd.read_csv(path, usecols=usecols, chunksize=chunksize, dtype=dtypes):\n",
    "        # normalize keys in the chunk\n",
    "        c1 = chunk[k1].astype(\"string\")\n",
    "        c2 = pd.to_numeric(chunk[k2], errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "        composite = (c1.astype(\"string\") + \"|\" + c2.astype(\"string\"))\n",
    "        mask = composite.isin(keep_set)\n",
    "\n",
    "        sel = chunk.loc[mask]\n",
    "        if not sel.empty:\n",
    "            parts.append(sel)\n",
    "\n",
    "    return pd.concat(parts, ignore_index=True) if parts else pd.DataFrame(columns=usecols)\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Build impressions for selected users \n",
    "# ---------------------------\n",
    "def collect_impressions_for_users(imp_path, selected_users, chunksize=CHUNKSIZE):\n",
    "    usecols = [\n",
    "        \"userId\",\"mlogId\",\"impressTime\",\"dt\",\"impressPosition\",\n",
    "        \"isClick\",\"isLike\",\"isComment\",\"isShare\",\"isViewComment\",\n",
    "        \"isIntoPersonalHomepage\",\"mlogViewTime\"\n",
    "    ]\n",
    "    dtypes = {\n",
    "        \"userId\": \"string\",\n",
    "        \"mlogId\": \"string\",\n",
    "        \"dt\": \"Int16\",\n",
    "        \"impressPosition\": \"Int16\",\n",
    "        \"isClick\": \"Int8\",\n",
    "        \"isLike\": \"Int8\",\n",
    "        \"isComment\": \"Int8\",\n",
    "        \"isShare\": \"Int8\",\n",
    "        \"isViewComment\": \"Int8\",\n",
    "        \"isIntoPersonalHomepage\": \"Int8\",\n",
    "        \"mlogViewTime\": \"float32\"\n",
    "    }\n",
    "    parts = []\n",
    "    for chunk in pd.read_csv(imp_path, usecols=usecols, chunksize=chunksize, dtype=dtypes):\n",
    "        sel = chunk[chunk[\"userId\"].isin(selected_users)]\n",
    "        if sel.empty:\n",
    "            continue\n",
    "        # Preserve early behavior ordering\n",
    "        sel = chunk[chunk[\"userId\"].isin(selected_users)].copy()\n",
    "        sel.sort_values([\"userId\", \"impressTime\"], inplace=True, kind=\"mergesort\")\n",
    "        parts.append(sel)\n",
    "    return pd.concat(parts, ignore_index=True) if parts else pd.DataFrame(columns=usecols)\n",
    "\n",
    "# ---------------------------\n",
    "# Post-merge hygiene\n",
    "# ---------------------------\n",
    "def cast_post_merge(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    if {\"userId\",\"mlogId\",\"impressTime\"}.issubset(df.columns):\n",
    "        df.drop_duplicates([\"userId\",\"mlogId\",\"impressTime\"], inplace=True)\n",
    "\n",
    "    for c in [\"isClick\",\"isLike\",\"isComment\",\"isShare\",\"isViewComment\",\"isIntoPersonalHomepage\"]:\n",
    "        if c in df:\n",
    "            df[c] = df[c].fillna(0).astype(\"uint8\")\n",
    "\n",
    "    if \"impressPosition\" in df:\n",
    "        df[\"impressPosition\"] = df[\"impressPosition\"].astype(\"Int16\")\n",
    "    if \"mlogViewTime\" in df:\n",
    "        df[\"mlogViewTime\"] = pd.to_numeric(df[\"mlogViewTime\"], errors=\"coerce\").astype(\"float32\")\n",
    "\n",
    "    for c in [\"gender\",\"province\",\"type\",\"contentId\",\"talkId\",\"creatorType\"]:\n",
    "        if c in df:\n",
    "            df[c] = df[c].astype(\"category\")\n",
    "\n",
    "    return df\n",
    "\n",
    "# ---------------------------\n",
    "# Main build\n",
    "# ---------------------------\n",
    "def main():\n",
    "    OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # 1) Explicitly select users with registeredMonthCnt == 0\n",
    "    selected_users = users_with_registered_month_zero(USR_PATH, chunksize=CHUNKSIZE)\n",
    "    print(f\"Users with registeredMonthCnt = 0: {len(selected_users):,}\")\n",
    "\n",
    "    # 2) Pull ALL impressions for those users \n",
    "    imp = collect_impressions_for_users(IMP_PATH, selected_users, CHUNKSIZE)\n",
    "    print(f\"Collected impressions: {len(imp):,}\")\n",
    "\n",
    "    # 3) Keys for joins\n",
    "    user_keys = imp[\"userId\"].astype(\"string\").unique()\n",
    "    mlog_keys = imp[\"mlogId\"].astype(\"string\").unique()\n",
    "\n",
    "    # 4) Read user/card/creator dims (static, leakage-free)\n",
    "    users = read_filtered(\n",
    "        USR_PATH, \"userId\", user_keys,\n",
    "        [\"userId\",\"age\",\"gender\",\"province\",\"level\",\"registeredMonthCnt\",\"followCnt\"]\n",
    "    )\n",
    "    cards = read_filtered(\n",
    "        CRD_PATH, \"mlogId\", mlog_keys,\n",
    "        [\"mlogId\",\"type\",\"contentId\",\"talkId\",\"publishTime\",\"creatorId\"]\n",
    "    )\n",
    "    creator_keys = cards[\"creatorId\"].dropna().astype(\"string\").unique() if not cards.empty else []\n",
    "    creators = read_filtered(\n",
    "        CRT_PATH, \"creatorId\", creator_keys,\n",
    "        [\"creatorId\",\"creatorType\",\"level\"]\n",
    "    )\n",
    "\n",
    "    # 5) Merge core dims\n",
    "    df = (imp\n",
    "          .merge(users, on=\"userId\", how=\"left\", suffixes=(\"\", \"_user\"))\n",
    "          .merge(cards, on=\"mlogId\", how=\"left\", suffixes=(\"\", \"_card\"))\n",
    "          .merge(creators, on=\"creatorId\", how=\"left\", suffixes=(\"\", \"_creator\"))\n",
    "          )\n",
    "\n",
    "    # 6) Rename levels and create label (as before)\n",
    "    if \"level\" in df.columns:\n",
    "        df.rename(columns={\"level\": \"user_level\"}, inplace=True)\n",
    "    if \"level_creator\" in df.columns:\n",
    "        df.rename(columns={\"level_creator\": \"creator_level\"}, inplace=True)\n",
    "    elif \"level_y\" in df.columns and \"creator_level\" not in df.columns:\n",
    "        df.rename(columns={\"level_y\": \"creator_level\"}, inplace=True)\n",
    "    if \"level_x\" in df.columns and \"user_level\" not in df.columns:\n",
    "        df.rename(columns={\"level_x\": \"user_level\"}, inplace=True)\n",
    "\n",
    "    if \"user_level\" in df.columns:\n",
    "        df[\"y_active\"] = (pd.to_numeric(df[\"user_level\"], errors=\"coerce\") >= 2).astype(\"uint8\")\n",
    "    else:\n",
    "        df[\"y_active\"] = np.nan\n",
    "\n",
    "    # 7) Merge mlog_stats on (mlogId, dt)\n",
    "    if not df.empty:\n",
    "        # Build pair keys from already-kept mlogId, dt\n",
    "        mlog_dt_pairs = df[[\"mlogId\", \"dt\"]].dropna().drop_duplicates().values.tolist()\n",
    "        mlog_stats = read_filtered_two_keys(\n",
    "            MLOG_STATS_PATH,\n",
    "            key_cols=(\"mlogId\", \"dt\"),\n",
    "            keep_pairs=mlog_dt_pairs,\n",
    "            usecols=[\n",
    "                \"mlogId\",\"dt\",\n",
    "                \"userImprssionCount\",\"userClickCount\",\"userLikeCount\",\n",
    "                \"userCommentCount\",\"userShareCount\",\"userViewCommentCount\",\n",
    "                \"userIntoPersonalHomepageCount\",\"userFollowCreatorCount\"\n",
    "            ],\n",
    "            dtypes={\"mlogId\": \"string\", \"dt\": \"Int64\"}\n",
    "        )\n",
    "        if not mlog_stats.empty:\n",
    "            # Cast dt to Int16 to match df\n",
    "            mlog_stats[\"dt\"] = mlog_stats[\"dt\"].astype(\"Int16\")\n",
    "            df = df.merge(mlog_stats, on=[\"mlogId\",\"dt\"], how=\"left\", suffixes=(\"\", \"_mlogstats\"))\n",
    "\n",
    "    # 8) Merge creator_stats on (creatorId, dt)\n",
    "    if not df.empty and \"creatorId\" in df.columns:\n",
    "        creator_dt_pairs = df[[\"creatorId\", \"dt\"]].dropna().drop_duplicates().values.tolist()\n",
    "        creator_stats = read_filtered_two_keys(\n",
    "            CREATOR_STATS_PATH,\n",
    "            key_cols=(\"creatorId\", \"dt\"),\n",
    "            keep_pairs=creator_dt_pairs,\n",
    "            usecols=[\"creatorId\",\"dt\",\"PushlishMlogCnt\"],   # keep the source's column name\n",
    "            dtypes={\"creatorId\": \"string\", \"dt\": \"Int64\"}\n",
    "        )\n",
    "        if not creator_stats.empty:\n",
    "            creator_stats[\"dt\"] = creator_stats[\"dt\"].astype(\"Int16\")\n",
    "            df = df.merge(creator_stats, on=[\"creatorId\",\"dt\"], how=\"left\", suffixes=(\"\", \"_creatorstats\"))\n",
    "\n",
    "    # 9) dtypes & hygiene\n",
    "    df = cast_post_merge(df)\n",
    "\n",
    "    # 10) Save\n",
    "    df.to_csv(OUT_CSV, index=False)\n",
    "    print(f\"Saved: {OUT_CSV}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "music-thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
