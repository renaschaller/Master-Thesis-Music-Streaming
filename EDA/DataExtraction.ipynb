{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "248cf193",
   "metadata": {},
   "source": [
    "## Data Cleaning and Merging\n",
    "\n",
    "### This script:\n",
    " 1) samples 100,000 impressions (chunked)\n",
    " 2) collects unique userId/mlogId/creatorId\n",
    " 3) filters user/card/creator tables to those keys\n",
    " 4) merges\n",
    " 5) saves CSV to \"data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4118291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled users: 15,000\n",
      "Collected impressions: 107,425 \n",
      "Saved: ../data/imp_sample_100k_merged.csv\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "# ---------------------------\n",
    "# Config\n",
    "# ---------------------------\n",
    "DATA_DIR = Path(\"../csv_data\")\n",
    "OUT_DIR = Path(\"../data\")\n",
    "OUT_CSV = OUT_DIR / \"imp_sample_100k_merged.csv\"\n",
    "\n",
    "# User-first sampling targets\n",
    "N_USERS = 15_000            # uniformly sample users for modeling & EDA\n",
    "MAX_IMPS_PER_USER = 10      # cap per-user impressions to ~100k total rows\n",
    "CHUNKSIZE = 250_000\n",
    "SEED = 42\n",
    "\n",
    "# File paths\n",
    "IMP_PATH = DATA_DIR / \"impression_data.csv\"\n",
    "USR_PATH = DATA_DIR / \"user_demographics.csv\"\n",
    "CRD_PATH = DATA_DIR / \"mlog_demographics.csv\"\n",
    "CRT_PATH = DATA_DIR / \"creator_demographics.csv\"\n",
    "\n",
    "# ---------------------------\n",
    "# Reservoir sampling of users\n",
    "# ---------------------------\n",
    "def sample_users_uniform(user_csv, n_users=N_USERS, chunksize=CHUNKSIZE, seed=SEED):\n",
    "    \"\"\"\n",
    "    Uniform sampling over all users listed in user_demographics.csv via reservoir sampling.\n",
    "    Each userId is considered exactly once (no bias from impression frequency).\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    reservoir = []\n",
    "    seen = 0\n",
    "    usecols = [\"userId\"]  # minimal read\n",
    "    for chunk in pd.read_csv(user_csv, usecols=usecols, chunksize=chunksize, dtype={\"userId\": \"string\"}):\n",
    "        for u in chunk[\"userId\"]:\n",
    "            if pd.isna(u):\n",
    "                continue\n",
    "            seen += 1\n",
    "            if len(reservoir) < n_users:\n",
    "                reservoir.append(u)\n",
    "            else:\n",
    "                j = rng.integers(0, seen)\n",
    "                if j < n_users:\n",
    "                    reservoir[j] = u\n",
    "    return set(reservoir)\n",
    "\n",
    "# ---------------------------\n",
    "# Read helpers (filtered joins)\n",
    "# ---------------------------\n",
    "def read_filtered(path, key_col, keep_keys, usecols, chunksize=CHUNKSIZE):\n",
    "    keep_keys = {str(x) for x in pd.Series(list(keep_keys)).dropna().unique()}\n",
    "    parts = []\n",
    "    for chunk in pd.read_csv(path, usecols=usecols, chunksize=chunksize, dtype={key_col: \"string\"}):\n",
    "        chunk[key_col] = chunk[key_col].astype(\"string\")\n",
    "        sel = chunk[chunk[key_col].isin(keep_keys)]\n",
    "        if not sel.empty:\n",
    "            parts.append(sel)\n",
    "    return pd.concat(parts, ignore_index=True) if parts else pd.DataFrame(columns=usecols)\n",
    "\n",
    "# ---------------------------\n",
    "# Build impressions for sampled users\n",
    "# ---------------------------\n",
    "def collect_impressions_for_users(imp_path, sampled_users, max_imps_per_user=MAX_IMPS_PER_USER,\n",
    "                                  chunksize=CHUNKSIZE):\n",
    "    usecols = [\n",
    "        \"userId\",\"mlogId\",\"impressTime\",\"dt\",\"impressPosition\",\n",
    "        \"isClick\",\"isLike\",\"isComment\",\"isShare\",\"isViewComment\",\n",
    "        \"isIntoPersonalHomepage\",\"mlogViewTime\"\n",
    "    ]\n",
    "    dtypes = {\n",
    "        \"userId\": \"string\",\n",
    "        \"mlogId\": \"string\",\n",
    "        \"dt\": \"Int16\",\n",
    "        \"impressPosition\": \"Int16\",\n",
    "        \"isClick\": \"Int8\",\n",
    "        \"isLike\": \"Int8\",\n",
    "        \"isComment\": \"Int8\",\n",
    "        \"isShare\": \"Int8\",\n",
    "        \"isViewComment\": \"Int8\",\n",
    "        \"isIntoPersonalHomepage\": \"Int8\",\n",
    "        \"mlogViewTime\": \"float32\"\n",
    "    }\n",
    "    per_user_count = defaultdict(int)\n",
    "    parts = []\n",
    "\n",
    "    for chunk in pd.read_csv(imp_path, usecols=usecols, chunksize=chunksize, dtype=dtypes):\n",
    "        chunk = chunk[chunk[\"userId\"].isin(sampled_users)]\n",
    "        if chunk.empty:\n",
    "            continue\n",
    "        # Order by time to keep early behavior meaningful\n",
    "        chunk.sort_values([\"userId\", \"impressTime\"], inplace=True, kind=\"mergesort\")\n",
    "\n",
    "        # Apply per-user cap \n",
    "        keep_mask = []\n",
    "        for u in chunk[\"userId\"]:\n",
    "            c = per_user_count[u]\n",
    "            keep = c < max_imps_per_user\n",
    "            keep_mask.append(keep)\n",
    "            if keep:\n",
    "                per_user_count[u] = c + 1\n",
    "\n",
    "        kept = chunk.loc[keep_mask]\n",
    "        if not kept.empty:\n",
    "            parts.append(kept)\n",
    "\n",
    "        # Early stop if everyone reached cap \n",
    "        if len(per_user_count) >= len(sampled_users) and all(\n",
    "            per_user_count[u] >= max_imps_per_user for u in sampled_users\n",
    "        ):\n",
    "            break\n",
    "\n",
    "    if not parts:\n",
    "        return pd.DataFrame(columns=usecols)\n",
    "    return pd.concat(parts, ignore_index=True)\n",
    "\n",
    "# ---------------------------\n",
    "# Post-merge hygiene\n",
    "# ---------------------------\n",
    "def cast_post_merge(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    if {\"userId\",\"mlogId\",\"impressTime\"}.issubset(df.columns):\n",
    "        df.drop_duplicates([\"userId\",\"mlogId\",\"impressTime\"], inplace=True)\n",
    "\n",
    "    # booleans to uint8\n",
    "    for c in [\"isClick\",\"isLike\",\"isComment\",\"isShare\",\"isViewComment\",\"isIntoPersonalHomepage\"]:\n",
    "        if c in df:\n",
    "            df[c] = df[c].fillna(0).astype(\"uint8\")\n",
    "\n",
    "    # numerics\n",
    "    if \"impressPosition\" in df:\n",
    "        df[\"impressPosition\"] = df[\"impressPosition\"].astype(\"Int16\")\n",
    "    if \"mlogViewTime\" in df:\n",
    "        df[\"mlogViewTime\"] = pd.to_numeric(df[\"mlogViewTime\"], errors=\"coerce\").astype(\"float32\")\n",
    "\n",
    "    # categoricals for memory\n",
    "    for c in [\"gender\",\"province\",\"type\",\"contentId\",\"talkId\",\"creatorType\"]:\n",
    "        if c in df:\n",
    "            df[c] = df[c].astype(\"category\")\n",
    "\n",
    "    return df\n",
    "\n",
    "# ---------------------------\n",
    "# Main build\n",
    "# ---------------------------\n",
    "def main():\n",
    "    OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # 1) Uniformly sample users \n",
    "    sampled_users = sample_users_uniform(USR_PATH, n_users=N_USERS, chunksize=CHUNKSIZE, seed=SEED)\n",
    "    print(f\"Sampled users: {len(sampled_users):,}\")\n",
    "\n",
    "    # 2) Pull up impressions per sampled user\n",
    "    imp = collect_impressions_for_users(IMP_PATH, sampled_users, MAX_IMPS_PER_USER, CHUNKSIZE)\n",
    "    print(f\"Collected impressions: {len(imp):,} \")\n",
    "\n",
    "    # 3) Keys for joins\n",
    "    user_keys = imp[\"userId\"].astype(\"string\").unique()\n",
    "    mlog_keys = imp[\"mlogId\"].astype(\"string\").unique()\n",
    "\n",
    "    # 4) Read user/card/creator dims (static, leakage-free)\n",
    "    users = read_filtered(\n",
    "        USR_PATH, \"userId\", user_keys,\n",
    "        [\"userId\",\"age\",\"gender\",\"province\",\"level\",\"registeredMonthCnt\",\"followCnt\"]\n",
    "    )\n",
    "    cards = read_filtered(\n",
    "        CRD_PATH, \"mlogId\", mlog_keys,\n",
    "        [\"mlogId\",\"type\",\"contentId\",\"talkId\",\"publishTime\",\"creatorId\"]\n",
    "    )\n",
    "    creator_keys = cards[\"creatorId\"].dropna().astype(\"string\").unique() if not cards.empty else []\n",
    "    creators = read_filtered(\n",
    "        CRT_PATH, \"creatorId\", creator_keys,\n",
    "        [\"creatorId\",\"creatorType\",\"level\"]\n",
    "    )\n",
    "\n",
    "    # 5) Merge\n",
    "    df = (imp\n",
    "          .merge(users, on=\"userId\", how=\"left\", suffixes=(\"\", \"_user\"))\n",
    "          .merge(cards, on=\"mlogId\", how=\"left\", suffixes=(\"\", \"_card\"))\n",
    "          .merge(creators, on=\"creatorId\", how=\"left\", suffixes=(\"\", \"_creator\"))\n",
    "          )\n",
    "\n",
    "    # 6) Rename levels and create label\n",
    "    if \"level\" in df.columns:\n",
    "        df.rename(columns={\"level\": \"user_level\"}, inplace=True)\n",
    "    if \"level_creator\" in df.columns:\n",
    "        df.rename(columns={\"level_creator\": \"creator_level\"}, inplace=True)\n",
    "    elif \"level_y\" in df.columns and \"creator_level\" not in df.columns:\n",
    "        df.rename(columns={\"level_y\": \"creator_level\"}, inplace=True)\n",
    "    if \"level_x\" in df.columns and \"user_level\" not in df.columns:\n",
    "        df.rename(columns={\"level_x\": \"user_level\"}, inplace=True)\n",
    "\n",
    "    # Binary label: active if user_level >= 5\n",
    "    if \"user_level\" in df.columns:\n",
    "        df[\"y_active\"] = (pd.to_numeric(df[\"user_level\"], errors=\"coerce\") >= 5).astype(\"uint8\")\n",
    "    else:\n",
    "        df[\"y_active\"] = np.nan\n",
    "\n",
    "    # 7) dtypes\n",
    "    df = cast_post_merge(df)\n",
    "\n",
    "    # 8) Save\n",
    "    df.to_csv(OUT_CSV, index=False)\n",
    "    print(f\"Saved: {OUT_CSV}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52fede66",
   "metadata": {},
   "source": [
    "#### Sanity Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3f8c79f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows:  107425\n",
      "Users:  15000\n",
      "Cards:  12019\n",
      "Creators:  7056\n",
      "Null rates:  age            0.364\n",
      "gender         0.364\n",
      "province       0.000\n",
      "type           0.000\n",
      "contentId      0.134\n",
      "talkId         0.000\n",
      "creatorType    0.000\n",
      "dtype: float64\n",
      "Clicks:  3456 17\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/imp_sample_100k_merged.csv\")\n",
    "# 1) Should be ~100,000 rows\n",
    "length=len(df)\n",
    "print(\"Rows: \",length)\n",
    "\n",
    "# 2) How many unique users/cards/creators in the sample?\n",
    "print(\"Users: \",df[\"userId\"].nunique())\n",
    "print(\"Cards: \",df[\"mlogId\"].nunique())\n",
    "print(\"Creators: \",df[\"creatorId\"].nunique())\n",
    "\n",
    "# 3) Null rates on key columns\n",
    "print(\"Null rates: \",df[[\"age\",\"gender\",\"province\",\"type\",\"contentId\",\"talkId\",\"creatorType\"]].isna().mean().round(3))\n",
    "\n",
    "# 4) Spot-check that clicks exist\n",
    "print(\"Clicks: \",df[\"isClick\"].sum(), df[\"isShare\"].sum())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "music-thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
