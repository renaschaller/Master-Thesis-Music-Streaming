{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "248cf193",
   "metadata": {},
   "source": [
    "## Data Cleaning and Merging\n",
    "\n",
    "### This script:\n",
    " 1) samples 100,000 impressions (chunked)\n",
    " 2) collects unique userId/mlogId/creatorId\n",
    " 3) filters user/card/creator tables to those keys\n",
    " 4) merges\n",
    " 5) saves CSV to \"data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4118291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ../data/imp_sample_100k_merged.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "DATA_DIR = Path(\"../csv_data\")\n",
    "OUT_DIR = Path(\"../data\")\n",
    "N = 100_000\n",
    "CHUNKSIZE = 250_000\n",
    "SEED = 42\n",
    "\n",
    "# File paths\n",
    "IMP_PATH = DATA_DIR / \"impression_data.csv\"\n",
    "USR_PATH = DATA_DIR / \"user_demographics.csv\"\n",
    "CRD_PATH = DATA_DIR / \"mlog_demographics.csv\"\n",
    "CRT_PATH = DATA_DIR / \"creator_demographics.csv\"\n",
    "\n",
    "def sample_impressions(path, n=N, chunksize=CHUNKSIZE, seed=SEED):\n",
    "    cols = [\n",
    "        \"userId\",\"mlogId\",\"impressTime\",\"dt\",\"impressPosition\",\n",
    "        \"isClick\",\"isLike\",\"isComment\",\"isShare\",\"isViewComment\",\"mlogViewTime\"\n",
    "    ]\n",
    "    taken = 0\n",
    "    parts = []\n",
    "    for i, chunk in enumerate(pd.read_csv(path, usecols=cols, chunksize=chunksize)):\n",
    "        need = n - taken\n",
    "        if need <= 0:\n",
    "            break\n",
    "        k = min(need, len(chunk))\n",
    "        parts.append(chunk.sample(n=k, random_state=seed + i))\n",
    "        taken += k\n",
    "    if not parts:\n",
    "        return pd.DataFrame(columns=cols)\n",
    "    return pd.concat(parts, ignore_index=True)\n",
    "\n",
    "def read_filtered(path, key_col, keep_keys, usecols, chunksize=CHUNKSIZE):\n",
    "    keep_keys = set(str(x) for x in keep_keys)\n",
    "    out_parts = []\n",
    "    for chunk in pd.read_csv(path, usecols=usecols, chunksize=chunksize):\n",
    "        chunk[key_col] = chunk[key_col].astype(str)\n",
    "        out = chunk[chunk[key_col].isin(keep_keys)]\n",
    "        if not out.empty:\n",
    "            out_parts.append(out)\n",
    "    if out_parts:\n",
    "        return pd.concat(out_parts, ignore_index=True)\n",
    "    return pd.DataFrame(columns=usecols)\n",
    "\n",
    "def main():\n",
    "    OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # 1) Base sample\n",
    "    imp = sample_impressions(IMP_PATH)\n",
    "\n",
    "    # 2) Unique keys\n",
    "    user_keys = imp[\"userId\"].astype(str).unique()\n",
    "    mlog_keys = imp[\"mlogId\"].astype(str).unique()\n",
    "\n",
    "    # 3) Filter dimension tables\n",
    "    users = read_filtered(\n",
    "        USR_PATH, \"userId\", user_keys,\n",
    "        [\"userId\",\"age\",\"gender\",\"province\",\"level\",\"registeredMonthCnt\",\"followCnt\"]\n",
    "    )\n",
    "    cards = read_filtered(\n",
    "        CRD_PATH, \"mlogId\", mlog_keys,\n",
    "        [\"mlogId\",\"type\",\"contentId\",\"talkId\",\"publishTime\",\"creatorId\"]\n",
    "    )\n",
    "    creator_keys = cards[\"creatorId\"].dropna().astype(str).unique()\n",
    "    creators = read_filtered(\n",
    "        CRT_PATH, \"creatorId\", creator_keys,\n",
    "        [\"creatorId\",\"creatorType\",\"level\"]\n",
    "    )\n",
    "\n",
    "    # 4) Merge\n",
    "    df = (imp\n",
    "          .merge(users, on=\"userId\", how=\"left\")\n",
    "          .merge(cards, on=\"mlogId\", how=\"left\")\n",
    "          .merge(creators, on=\"creatorId\", how=\"left\"))\n",
    "\n",
    "    # 5) Save CSV\n",
    "    out_csv = OUT_DIR / \"imp_sample_100k_merged.csv\"\n",
    "    df = df.rename(columns={\"level_x\":\"user_level\",\"level_y\":\"creator_level\"})\n",
    "    df.to_csv(out_csv, index=False)\n",
    "    print(f\"Saved: {out_csv}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "path = Path(\"/mnt/data/build_eda_sample_simple.py\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52fede66",
   "metadata": {},
   "source": [
    "#### Sanity Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3f8c79f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows:  100000\n",
      "Users:  9096\n",
      "Cards:  21264\n",
      "Creators:  10781\n",
      "Null rates:  age            0.373\n",
      "gender         0.373\n",
      "province       0.000\n",
      "type           0.000\n",
      "contentId      0.172\n",
      "talkId         0.000\n",
      "creatorType    0.000\n",
      "dtype: float64\n",
      "Clicks:  4805 23\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/imp_sample_100k_merged.csv\")\n",
    "# 1) Should be ~100,000 rows\n",
    "length=len(df)\n",
    "print(\"Rows: \",length)\n",
    "\n",
    "# 2) How many unique users/cards/creators in the sample?\n",
    "print(\"Users: \",df[\"userId\"].nunique())\n",
    "print(\"Cards: \",df[\"mlogId\"].nunique())\n",
    "print(\"Creators: \",df[\"creatorId\"].nunique())\n",
    "\n",
    "# 3) Null rates on key columns\n",
    "print(\"Null rates: \",df[[\"age\",\"gender\",\"province\",\"type\",\"contentId\",\"talkId\",\"creatorType\"]].isna().mean().round(3))\n",
    "\n",
    "# 4) Spot-check that clicks exist\n",
    "print(\"Clicks: \",df[\"isClick\"].sum(), df[\"isShare\"].sum())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "music-thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
