{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4efdd0c3",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c0b19a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV ROC AUC:   0.5945 ± 0.0018\n",
      "CV PR  AUC:   0.5925 ± 0.0016\n",
      "CV Accuracy:  0.5804 ± 0.0016\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'round'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 112\u001b[39m\n\u001b[32m    109\u001b[39m proba = pipe.predict_proba(X_test)[:,\u001b[32m1\u001b[39m]\n\u001b[32m    110\u001b[39m pred  = (proba >= \u001b[32m0.5\u001b[39m).astype(\u001b[38;5;28mint\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m112\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mHold-out ROC AUC:\u001b[39m\u001b[33m\"\u001b[39m, roc_auc_score(y_test, proba).round(\u001b[32m4\u001b[39m))\n\u001b[32m    113\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mHold-out PR  AUC:\u001b[39m\u001b[33m\"\u001b[39m, average_precision_score(y_test, proba).round(\u001b[32m4\u001b[39m))\n\u001b[32m    114\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mClassification report (threshold=0.5):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m, classification_report(y_test, pred, digits=\u001b[32m3\u001b[39m))\n",
      "\u001b[31mAttributeError\u001b[39m: 'float' object has no attribute 'round'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_validate\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, average_precision_score, classification_report,\n",
    "    RocCurveDisplay, PrecisionRecallDisplay\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# -------------------------\n",
    "# Load data\n",
    "# -------------------------\n",
    "PATH = Path(\"../data/cleaned_data.csv\")\n",
    "df = pd.read_csv(PATH)\n",
    "\n",
    "# Target\n",
    "y = df[\"y_active\"].astype(int)\n",
    "\n",
    "# Columns to drop (IDs/timestamps/high-cardinality identifiers that don’t generalize)\n",
    "drop_cols = [c for c in [\n",
    "    \"y_active\",\"mlogId\",\"userId\",\"creatorId\",\"contentId\",\"talkId\",\n",
    "    \"day\"  # date as timestamp; use engineered time features instead\n",
    "] if c in df.columns]\n",
    "\n",
    "X = df.drop(columns=drop_cols, errors=\"ignore\")\n",
    "\n",
    "# -------------------------\n",
    "# Split\n",
    "# -------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# Column typing\n",
    "# -------------------------\n",
    "# treat as categorical: pandas object/category/string or small-cardinality integer-like labels\n",
    "cat_cols = (\n",
    "    list(X_train.select_dtypes(include=[\"object\",\"category\",\"string\",\"bool\"]).columns)\n",
    ")\n",
    "\n",
    "# additionally, mark integer columns with few unique values as categorical (e.g., type, creatorType)\n",
    "for c in X_train.select_dtypes(include=[\"int16\",\"int32\",\"int64\",\"Int8\",\"Int16\",\"Int32\",\"Int64\",\"uint8\",\"uint16\"]).columns:\n",
    "    if X_train[c].nunique(dropna=True) <= 20:  # small cardinality → categorical\n",
    "        if c not in cat_cols:\n",
    "            cat_cols.append(c)\n",
    "\n",
    "num_cols = [c for c in X_train.columns if c not in cat_cols]\n",
    "\n",
    "# -------------------------\n",
    "# Preprocess\n",
    "# -------------------------\n",
    "num_pipe = Pipeline(steps=[\n",
    "    (\"impute\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scale\", StandardScaler(with_mean=True, with_std=True)),\n",
    "])\n",
    "\n",
    "cat_pipe = Pipeline(steps=[\n",
    "    (\"impute\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"oh\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))\n",
    "])\n",
    "\n",
    "pre = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", num_pipe, num_cols),\n",
    "        (\"cat\", cat_pipe, cat_cols),\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    "    n_jobs=None\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# Model\n",
    "# -------------------------\n",
    "logit = LogisticRegression(\n",
    "    max_iter=1000,\n",
    "    class_weight=\"balanced\",   # helps if classes are imbalanced\n",
    "    solver=\"lbfgs\",\n",
    "    n_jobs=None\n",
    ")\n",
    "\n",
    "pipe = Pipeline(steps=[(\"pre\", pre), (\"model\", logit)])\n",
    "\n",
    "# -------------------------\n",
    "# Cross-validation on train\n",
    "# -------------------------\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_scores = cross_validate(\n",
    "    pipe, X_train, y_train, cv=cv,\n",
    "    scoring={\"roc_auc\":\"roc_auc\", \"pr_auc\":\"average_precision\", \"acc\":\"accuracy\"},\n",
    "    n_jobs=None, return_train_score=False\n",
    ")\n",
    "\n",
    "print(\"CV ROC AUC:  \", np.mean(cv_scores[\"test_roc_auc\"]).round(4), \"±\", np.std(cv_scores[\"test_roc_auc\"]).round(4))\n",
    "print(\"CV PR  AUC:  \", np.mean(cv_scores[\"test_pr_auc\"]).round(4), \"±\", np.std(cv_scores[\"test_pr_auc\"]).round(4))\n",
    "print(\"CV Accuracy: \", np.mean(cv_scores[\"test_acc\"]).round(4), \"±\", np.std(cv_scores[\"test_acc\"]).round(4))\n",
    "\n",
    "# -------------------------\n",
    "# Fit on train, evaluate on hold-out\n",
    "# -------------------------\n",
    "pipe.fit(X_train, y_train)\n",
    "proba = pipe.predict_proba(X_test)[:,1]\n",
    "pred  = (proba >= 0.5).astype(int)\n",
    "\n",
    "print(\"\\nHold-out ROC AUC:\", roc_auc_score(y_test, proba).round(4))\n",
    "print(\"Hold-out PR  AUC:\", average_precision_score(y_test, proba).round(4))\n",
    "print(\"\\nClassification report (threshold=0.5):\\n\", classification_report(y_test, pred, digits=3))\n",
    "\n",
    "# Curves\n",
    "RocCurveDisplay.from_predictions(y_test, proba)\n",
    "plt.title(\"ROC curve (Logistic Regression)\"); plt.show()\n",
    "\n",
    "PrecisionRecallDisplay.from_predictions(y_test, proba)\n",
    "plt.title(\"Precision-Recall (Logistic Regression)\"); plt.show()\n",
    "\n",
    "# -------------------------\n",
    "# Optional: show top coefficients\n",
    "# -------------------------\n",
    "# Build feature names after one-hot\n",
    "oh = pipe.named_steps[\"pre\"].named_transformers_[\"cat\"].named_steps[\"oh\"]\n",
    "cat_feature_names = oh.get_feature_names_out(cat_cols) if len(cat_cols) else np.array([])\n",
    "feature_names = np.r_[num_cols, cat_feature_names]\n",
    "\n",
    "coefs = pipe.named_steps[\"model\"].coef_.ravel()\n",
    "coef_df = pd.DataFrame({\"feature\": feature_names, \"coef\": coefs}).sort_values(\"coef\", ascending=False)\n",
    "\n",
    "print(\"\\nTop positive features:\\n\", coef_df.head(15).to_string(index=False))\n",
    "print(\"\\nTop negative features:\\n\", coef_df.tail(15).to_string(index=False))\n",
    "\n",
    "# -------------------------\n",
    "# Save model (optional)\n",
    "# -------------------------\n",
    "# import joblib\n",
    "# joblib.dump(pipe, \"../data/logreg_pipeline.pkl\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "music-thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
